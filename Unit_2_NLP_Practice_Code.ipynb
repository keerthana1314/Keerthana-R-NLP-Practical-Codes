{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRg7kBiOx6SX",
        "outputId": "598847cf-4671-4eb1-9d72-7600aed496bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "147gLQw3yTXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"meeting\"\n",
        "lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "print(f\"Lemmatized Word:{lemma}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JerCG976ynRz",
        "outputId": "d348e300-88e7-4dbc-a50f-9df70ad8e11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Word:meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvgB02XL1LCL",
        "outputId": "42e9f5ce-a899-47c3-bae2-8b44e09ce06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "90J7aobu1ZB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"flew\"\n",
        "lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "print(f\"Lemmatized Word:{lemma}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO55dd0A1g9a",
        "outputId": "16218335-105b-42a4-87f9-6f2e2827469a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Word:fly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF_aXMPu2IIE",
        "outputId": "92509b95-3623-4e9e-a13d-a8f88d64e743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "ZBCQGDQA2NNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"drawing\"\n",
        "lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "print(f\"Lemmatized Word:{lemma}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ql-YRa2Qap",
        "outputId": "34f2e9b2-9a65-40c0-ee3f-1eb660213f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Word:draw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOTJAcov2YSC",
        "outputId": "5d5f1fd0-de43-4d65-84e0-cc1fe54e2cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "oc326RTJ2bO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"ran\"\n",
        "lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "print(f\"Lemmatized Word:{lemma}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm-yjAHQ2eks",
        "outputId": "829affdb-2180-4e41-8d5a-8fb232ffae60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Word:run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "VDDP_f502lgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63452650-8d27-4e55-c9e0-6a3d7ba88d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "VnSAr6JH2n1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"drawn\"\n",
        "lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "print(f\"Lemmatized Word:{lemma}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLhBqYEM2qsa",
        "outputId": "6ced3ede-4586-4cdf-e8ea-7acdb0460875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Word:draw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as Wn\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "XFWSGzK_3gEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "sentence = \"The dogs are running\"\n",
        "tokens = word_tokenize(sentence)\n",
        "tagged = pos_tag(tokens)"
      ],
      "metadata": {
        "id": "3UUuSvFM4ZAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word, pos = 'v' if tag.startswith('v')else 'n') for word, tag in tagged]\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "id": "eXd0zBTs9iY7",
        "outputId": "c72292b2-8c2a-4d7d-f252-553fda4b57b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'dog', 'are', 'running']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as Wn\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "m1J9sLvQ6714"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "sentence = \"I am Studying Books\"\n",
        "tokens = word_tokenize(sentence)\n",
        "tagged = pos_tag(tokens)"
      ],
      "metadata": {
        "id": "Z2_1A_Bo7Aqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word, pos = 'v' if tag.startswith('v')else 'n') for word, tag in tagged]\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgoZgVRe7DMe",
        "outputId": "fb60e05c-19b5-468b-9e0c-1f394d2be5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'am', 'Studying', 'Books']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAPoE011eDVR",
        "outputId": "32eeb876-c6af-4ba1-91c3-99969282a5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"NLTK is a powerful library for natural language processing.\"\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "AovCZ3_ReMB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = pos_tag(words)"
      ],
      "metadata": {
        "id": "r8rV4iaAe1Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Taxt:\")\n",
        "print(text)\n",
        "\n",
        "print(\"\\nPOS Tagging Result:\")\n",
        "for word, pos_tags in pos_tags:\n",
        "    print(f\"{word}: {pos_tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iyj8fTFe4HZ",
        "outputId": "fce187e5-6238-4e4a-9237-d4af89351018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Taxt:\n",
            "NLTK is a powerful library for natural language processing.\n",
            "\n",
            "POS Tagging Result:\n",
            "NLTK: NNP\n",
            "is: VBZ\n",
            "a: DT\n",
            "powerful: JJ\n",
            "library: NN\n",
            "for: IN\n",
            "natural: JJ\n",
            "language: NN\n",
            "processing: NN\n",
            ".: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The quick brown for jumps over the lazy dog.\"\n",
        "words = word_tokenize(text)\n",
        "\n",
        "pos_tags = pos_tag(words)\n",
        "\n",
        "print(\"Original Taxt:\")\n",
        "print(text)\n",
        "\n",
        "print(\"\\nPOS Tagging Result:\")\n",
        "for word, pos_tags in pos_tags:\n",
        "    print(f\"{word}: {pos_tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsaqTPU0e7ox",
        "outputId": "c006d451-be55-4452-bdd3-1c14d1665568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Taxt:\n",
            "The quick brown for jumps over the lazy dog.\n",
            "\n",
            "POS Tagging Result:\n",
            "The: DT\n",
            "quick: JJ\n",
            "brown: NN\n",
            "for: IN\n",
            "jumps: NNS\n",
            "over: IN\n",
            "the: DT\n",
            "lazy: JJ\n",
            "dog: NN\n",
            ".: .\n"
          ]
        }
      ]
    }
  ]
}